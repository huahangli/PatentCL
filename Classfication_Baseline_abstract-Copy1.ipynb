{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# torch.cuda.set_device()                            #　指定gpu1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "EPOCHS = 1\n",
    "MAX_TOKEN_COUNT = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 2min 51s, total: 3min 29s\n",
      "Wall time: 58.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['A41D', 'A62B', 'A41B', 'D06N', 'A42B', 'A43B', 'D06B', 'A41F', 'E03D',\n",
       "       'A47K',\n",
       "       ...\n",
       "       'Y02D', 'F24V', 'H04T', 'G16B', 'G16C', 'G16Z', 'G21J', 'G16Y', 'G06J',\n",
       "       'E99Z'],\n",
       "      dtype='object', length=664)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "train_df=pd.read_feather(\"./autodl-nas/USPTO-2M_Training.feather\")\n",
    "val_df=pd.read_feather(\"./autodl-nas/USPTO-2M_Validation.feather\")\n",
    "\n",
    "LABEL_COLUMNS=train_df.columns[11:]\n",
    "LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pass pandas dataframe, and tokeizer along with the max token length[128 default]\n",
    "    \n",
    "    Example: \n",
    "    -------\n",
    "    train_dataset = ToxicCommentsDataset(\n",
    "      train_df,\n",
    "      tokenizer,\n",
    "      max_token_len=MAX_TOKEN_COUNT\n",
    "    )\n",
    "\n",
    "    sample_item = train_dataset[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: BertTokenizer,\n",
    "        max_token_len: int = 512,\n",
    "        test= False\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        self.test = test\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        comment_text = data_row.abstract\n",
    "\n",
    "        if not self.test:\n",
    "            labels = data_row[LABEL_COLUMNS]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            max_length=self.max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            add_special_tokens=True, # [CLS] & [SEP]\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True, #attention_mask\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        if not self.test:\n",
    "            return dict(\n",
    "            comment_text=comment_text,\n",
    "            input_ids = encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )\n",
    "        else:\n",
    "            return dict(\n",
    "                comment_text=comment_text,\n",
    "                input_ids = encoding[\"input_ids\"].flatten(),\n",
    "                attention_mask=encoding[\"attention_mask\"].flatten()\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PatentDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "val_dataset = PatentDataset(\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,drop_last = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True) #load the pretrained bert model\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes) # add a linear layer to the bert\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(self.dropout(output.last_hidden_state[:,0])) \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6376, 63760)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PatentTagger(len(LABEL_COLUMNS)).to(device)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "\n",
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 10\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate(mydataloader):\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "    #t0 = time.time()\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in tqdm(enumerate(mydataloader),total=len(mydataloader)):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)   \n",
    "\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                loss, outputs = model(input_ids, attention_mask, labels)\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "        total_loss = total_loss + loss.float().item()\n",
    "        outputs = outputs.detach().float().cpu().numpy()\n",
    "        labels = labels.detach().float().cpu().numpy()\n",
    "        total_preds.append(outputs)\n",
    "        total_labels.append(labels)\n",
    "\n",
    "    avg_loss = total_loss / len(mydataloader)\n",
    "\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    total_labels = np.concatenate(total_labels, axis=0)\n",
    "\n",
    "    print(f\"Evaluate loss {total_loss / len(mydataloader)}\")\n",
    "    model.train()\n",
    "    return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    now=time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "    best_valid_loss = float('inf')\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    avg_loss = 0\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in tqdm(enumerate(train_dataloader),total=len(train_dataloader),desc=\"Train\"):\n",
    "        \n",
    "        if step%5000 == 0 and step!=0:\n",
    "            valid_loss,_,_ = evaluate(val_dataloader)\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), f\"./model/Classfication_abstract_model{now}.pt\")\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)     \n",
    "\n",
    "        model.zero_grad() \n",
    "        with autocast():\n",
    "            loss, _ = model(input_ids, attention_mask, labels)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if step%200 == 0 :\n",
    "            print(f\"step: {step} loss: {loss}\")\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.float().item()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        scaler.update()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be0bb06db2041ffac883432edd839c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/63760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 loss: 0.013012336567044258\n",
      "step: 200 loss: 0.011891783215105534\n",
      "step: 400 loss: 0.009343056008219719\n",
      "step: 600 loss: 0.009999590925872326\n",
      "step: 800 loss: 0.011931704357266426\n",
      "step: 1000 loss: 0.01122819259762764\n",
      "step: 1200 loss: 0.009375101886689663\n",
      "step: 1400 loss: 0.00942588783800602\n",
      "step: 1600 loss: 0.009285036474466324\n",
      "step: 1800 loss: 0.010173646733164787\n",
      "step: 2000 loss: 0.009351005777716637\n",
      "step: 2200 loss: 0.007503061089664698\n",
      "step: 2400 loss: 0.006873880047351122\n",
      "step: 2600 loss: 0.0077779246494174\n",
      "step: 2800 loss: 0.006556471809744835\n",
      "step: 3000 loss: 0.008434687741100788\n",
      "step: 3200 loss: 0.006792544387280941\n",
      "step: 3400 loss: 0.007407904136925936\n",
      "step: 3600 loss: 0.008498935960233212\n",
      "step: 3800 loss: 0.0066587477922439575\n",
      "step: 4000 loss: 0.00875947531312704\n",
      "step: 4200 loss: 0.007214851677417755\n",
      "step: 4400 loss: 0.008076674304902554\n",
      "step: 4600 loss: 0.006552125792950392\n",
      "step: 4800 loss: 0.005467524752020836\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9915299bad743a58adf9628b993fcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.006815069757323288\n",
      "step: 5000 loss: 0.008045199327170849\n",
      "step: 5200 loss: 0.0067377216182649136\n",
      "step: 5400 loss: 0.006507044658064842\n",
      "step: 5600 loss: 0.008261529728770256\n",
      "step: 5800 loss: 0.005452746991068125\n",
      "step: 6000 loss: 0.007953728549182415\n",
      "step: 6200 loss: 0.005271097645163536\n",
      "step: 6400 loss: 0.006013098638504744\n",
      "step: 6600 loss: 0.007203992921859026\n",
      "step: 6800 loss: 0.005347018130123615\n",
      "step: 7000 loss: 0.006658430211246014\n",
      "step: 7200 loss: 0.00477381469681859\n",
      "step: 7400 loss: 0.00764570664614439\n",
      "step: 7600 loss: 0.006752817425876856\n",
      "step: 7800 loss: 0.006136501207947731\n",
      "step: 8000 loss: 0.00664351275190711\n",
      "step: 8200 loss: 0.007451686076819897\n",
      "step: 8400 loss: 0.005945117678493261\n",
      "step: 8600 loss: 0.005248998291790485\n",
      "step: 8800 loss: 0.0047660102136433125\n",
      "step: 9000 loss: 0.005224619060754776\n",
      "step: 9200 loss: 0.008080413565039635\n",
      "step: 9400 loss: 0.006035952363163233\n",
      "step: 9600 loss: 0.005716169252991676\n",
      "step: 9800 loss: 0.005177508573979139\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd0e4f7bb24cb9bc3dc2c054bfc600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005953713519825866\n",
      "step: 10000 loss: 0.007268458139151335\n",
      "step: 10200 loss: 0.0066675590351223946\n",
      "step: 10400 loss: 0.005758641287684441\n",
      "step: 10600 loss: 0.007122973911464214\n",
      "step: 10800 loss: 0.0056346808560192585\n",
      "step: 11000 loss: 0.005984003655612469\n",
      "step: 11200 loss: 0.005813052412122488\n",
      "step: 11400 loss: 0.006619095336645842\n",
      "step: 11600 loss: 0.0058076344430446625\n",
      "step: 11800 loss: 0.005591823719441891\n",
      "step: 12000 loss: 0.005130874924361706\n",
      "step: 12200 loss: 0.004638967104256153\n",
      "step: 12400 loss: 0.005352185107767582\n",
      "step: 12600 loss: 0.004926243796944618\n",
      "step: 12800 loss: 0.0036805050913244486\n",
      "step: 13000 loss: 0.006126330234110355\n",
      "step: 13200 loss: 0.003931519575417042\n",
      "step: 13400 loss: 0.006870080716907978\n",
      "step: 13600 loss: 0.005966171156615019\n",
      "step: 13800 loss: 0.005540113430470228\n",
      "step: 14000 loss: 0.00439738342538476\n",
      "step: 14200 loss: 0.007802925538271666\n",
      "step: 14400 loss: 0.004566485062241554\n",
      "step: 14600 loss: 0.007029811851680279\n",
      "step: 14800 loss: 0.006176281720399857\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854bbb3ca5ce44ec983e8b3734472794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005603812352242347\n",
      "step: 15000 loss: 0.004332813899964094\n",
      "step: 15200 loss: 0.006021414417773485\n",
      "step: 15400 loss: 0.007142563816159964\n",
      "step: 15600 loss: 0.006049643736332655\n",
      "step: 15800 loss: 0.0063386945985257626\n",
      "step: 16000 loss: 0.008851079270243645\n",
      "step: 16200 loss: 0.0046615912579\n",
      "step: 16400 loss: 0.0046090297400951385\n",
      "step: 16600 loss: 0.007102504372596741\n",
      "step: 16800 loss: 0.0035947379656136036\n",
      "step: 17000 loss: 0.006364994682371616\n",
      "step: 17200 loss: 0.005194767378270626\n",
      "step: 17400 loss: 0.0051585836336016655\n",
      "step: 17600 loss: 0.004730544053018093\n",
      "step: 17800 loss: 0.004860556684434414\n",
      "step: 18000 loss: 0.00579141266644001\n",
      "step: 18200 loss: 0.0035311204846948385\n",
      "step: 18400 loss: 0.0062245214357972145\n",
      "step: 18600 loss: 0.003741051536053419\n",
      "step: 18800 loss: 0.0049375686794519424\n",
      "step: 19000 loss: 0.00640818290412426\n",
      "step: 19200 loss: 0.005645744036883116\n",
      "step: 19400 loss: 0.005596559029072523\n",
      "step: 19600 loss: 0.0067101591266691685\n",
      "step: 19800 loss: 0.005679324269294739\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf34d0596ca4ec59640fad360321a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005389747303748684\n",
      "step: 20000 loss: 0.006330818869173527\n",
      "step: 20200 loss: 0.004385828971862793\n",
      "step: 20400 loss: 0.007502546068280935\n",
      "step: 20600 loss: 0.0041683632880449295\n",
      "step: 20800 loss: 0.0033431784249842167\n",
      "step: 21000 loss: 0.004914254881441593\n",
      "step: 21200 loss: 0.004825596231967211\n",
      "step: 21400 loss: 0.0045168763026595116\n",
      "step: 21600 loss: 0.005233236588537693\n",
      "step: 21800 loss: 0.005451945587992668\n",
      "step: 22000 loss: 0.0057573216035962105\n",
      "step: 22200 loss: 0.005049029365181923\n",
      "step: 22400 loss: 0.004306865390390158\n",
      "step: 22600 loss: 0.0040792734362185\n",
      "step: 22800 loss: 0.004799045622348785\n",
      "step: 23000 loss: 0.005034009926021099\n",
      "step: 23200 loss: 0.006072778720408678\n",
      "step: 23400 loss: 0.004694879520684481\n",
      "step: 23600 loss: 0.005839328747242689\n",
      "step: 23800 loss: 0.004436340648680925\n",
      "step: 24000 loss: 0.004902059677988291\n",
      "step: 24200 loss: 0.006690016482025385\n",
      "step: 24400 loss: 0.0039156232960522175\n",
      "step: 24600 loss: 0.004624576773494482\n",
      "step: 24800 loss: 0.004340296611189842\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4495c5f252439aa664658f0b82b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005251171837807057\n",
      "step: 25000 loss: 0.00492758909240365\n",
      "step: 25200 loss: 0.0044488622806966305\n",
      "step: 25400 loss: 0.006442800164222717\n",
      "step: 25600 loss: 0.005363112781196833\n",
      "step: 25800 loss: 0.005274486728012562\n",
      "step: 26000 loss: 0.005050510633736849\n",
      "step: 26200 loss: 0.007096807472407818\n",
      "step: 26400 loss: 0.005813184659928083\n",
      "step: 26600 loss: 0.005261649377644062\n",
      "step: 26800 loss: 0.006126993801444769\n",
      "step: 27000 loss: 0.006089768838137388\n",
      "step: 27200 loss: 0.006043876986950636\n",
      "step: 27400 loss: 0.007188380230218172\n",
      "step: 27600 loss: 0.004124113358557224\n",
      "step: 27800 loss: 0.004456973634660244\n",
      "step: 28000 loss: 0.004427823703736067\n",
      "step: 28200 loss: 0.005609849467873573\n",
      "step: 28400 loss: 0.005571182817220688\n",
      "step: 28600 loss: 0.0059096794575452805\n",
      "step: 28800 loss: 0.003748571965843439\n",
      "step: 29000 loss: 0.005998808890581131\n",
      "step: 29200 loss: 0.004879074636846781\n",
      "step: 29400 loss: 0.005019654519855976\n",
      "step: 29600 loss: 0.006490442901849747\n",
      "step: 29800 loss: 0.005066835321485996\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf8f7bb9aea4e599df2a00776b994a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.0051149421430225946\n",
      "step: 30000 loss: 0.004640503786504269\n",
      "step: 30200 loss: 0.004172858782112598\n",
      "step: 30400 loss: 0.00574825145304203\n",
      "step: 30600 loss: 0.005326497834175825\n",
      "step: 30800 loss: 0.006814407650381327\n",
      "step: 31000 loss: 0.005302960518747568\n",
      "step: 31200 loss: 0.004806051030755043\n",
      "step: 31400 loss: 0.004399290308356285\n",
      "step: 31600 loss: 0.0050444286316633224\n",
      "step: 31800 loss: 0.004456539172679186\n",
      "step: 32000 loss: 0.005154454614967108\n",
      "step: 32200 loss: 0.005295547656714916\n",
      "step: 32400 loss: 0.0042585572227835655\n",
      "step: 32600 loss: 0.003636320121586323\n",
      "step: 32800 loss: 0.005324679426848888\n",
      "step: 33000 loss: 0.0051211402751505375\n",
      "step: 33200 loss: 0.004130370449274778\n",
      "step: 33400 loss: 0.005866975523531437\n",
      "step: 33600 loss: 0.0037599392235279083\n",
      "step: 33800 loss: 0.005915570538491011\n",
      "step: 34000 loss: 0.00476113660261035\n",
      "step: 34200 loss: 0.003948139492422342\n",
      "step: 34400 loss: 0.005471607204526663\n",
      "step: 34600 loss: 0.004420747514814138\n",
      "step: 34800 loss: 0.003851537825539708\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e467dacb7bc046428d748f04f1541659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005039491854560182\n",
      "step: 35000 loss: 0.00545640429481864\n",
      "step: 35200 loss: 0.005337847862392664\n",
      "step: 35400 loss: 0.0046603321097791195\n",
      "step: 35600 loss: 0.006296766456216574\n",
      "step: 35800 loss: 0.0037575361784547567\n",
      "step: 36000 loss: 0.004595241975039244\n",
      "step: 36200 loss: 0.0038945460692048073\n",
      "step: 36400 loss: 0.005975418724119663\n",
      "step: 36600 loss: 0.005524842534214258\n",
      "step: 36800 loss: 0.005490224342793226\n",
      "step: 37000 loss: 0.004979349672794342\n",
      "step: 37200 loss: 0.0043941340409219265\n",
      "step: 37400 loss: 0.0036892457865178585\n",
      "step: 37600 loss: 0.00527940271422267\n",
      "step: 37800 loss: 0.005663914140313864\n",
      "step: 38000 loss: 0.0066391220316290855\n",
      "step: 38200 loss: 0.003922826610505581\n",
      "step: 38400 loss: 0.00482386676594615\n",
      "step: 38600 loss: 0.004781036172062159\n",
      "step: 38800 loss: 0.005157562904059887\n",
      "step: 39000 loss: 0.0039750817231833935\n",
      "step: 39200 loss: 0.004949135705828667\n",
      "step: 39400 loss: 0.006349786184728146\n",
      "step: 39600 loss: 0.004510027356445789\n",
      "step: 39800 loss: 0.0051185861229896545\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152329d979184e93991476d8e502a1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.004956234713436094\n",
      "step: 40000 loss: 0.005112936720252037\n",
      "step: 40200 loss: 0.005008650477975607\n",
      "step: 40400 loss: 0.004512897226959467\n",
      "step: 40600 loss: 0.005562123376876116\n",
      "step: 40800 loss: 0.005592006258666515\n",
      "step: 41000 loss: 0.00521506555378437\n",
      "step: 41200 loss: 0.005838092882186174\n",
      "step: 41400 loss: 0.002935917815193534\n",
      "step: 41600 loss: 0.005793129559606314\n",
      "step: 41800 loss: 0.004956494551151991\n",
      "step: 42000 loss: 0.004780573304742575\n",
      "step: 42200 loss: 0.0054644192568957806\n",
      "step: 42400 loss: 0.004579138942062855\n",
      "step: 42600 loss: 0.003436122788116336\n",
      "step: 42800 loss: 0.00514821894466877\n",
      "step: 43000 loss: 0.00443305354565382\n",
      "step: 43200 loss: 0.004611053038388491\n",
      "step: 43400 loss: 0.0035223786253482103\n",
      "step: 43600 loss: 0.00443147961050272\n",
      "step: 43800 loss: 0.003545920131728053\n",
      "step: 44000 loss: 0.005077302921563387\n",
      "step: 44200 loss: 0.005531689152121544\n",
      "step: 44400 loss: 0.004457431845366955\n",
      "step: 44600 loss: 0.004503726493567228\n",
      "step: 44800 loss: 0.004644840490072966\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56cc07248eb4f779edca99e0406d58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.00488225732501961\n",
      "step: 45000 loss: 0.005269747693091631\n",
      "step: 45200 loss: 0.004355178214609623\n",
      "step: 45400 loss: 0.006859550718218088\n",
      "step: 45600 loss: 0.006239450071007013\n",
      "step: 45800 loss: 0.005122290924191475\n",
      "step: 46000 loss: 0.005141776520758867\n",
      "step: 46200 loss: 0.004941432736814022\n",
      "step: 46400 loss: 0.004204892087727785\n",
      "step: 46600 loss: 0.005522429943084717\n",
      "step: 46800 loss: 0.00398195581510663\n",
      "step: 47000 loss: 0.0048233442939817905\n",
      "step: 47200 loss: 0.006000581197440624\n",
      "step: 47400 loss: 0.004472291562706232\n",
      "step: 47600 loss: 0.004456717986613512\n",
      "step: 47800 loss: 0.005124782212078571\n",
      "step: 48000 loss: 0.00549608888104558\n",
      "step: 48200 loss: 0.006880708038806915\n",
      "step: 48400 loss: 0.005162759684026241\n",
      "step: 48600 loss: 0.004704514052718878\n",
      "step: 48800 loss: 0.006212571635842323\n",
      "step: 49000 loss: 0.005357827991247177\n",
      "step: 49200 loss: 0.005283455364406109\n",
      "step: 49400 loss: 0.0057135834358632565\n",
      "step: 49600 loss: 0.0058306255377829075\n",
      "step: 49800 loss: 0.004563144873827696\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dd5918d8464ff199ba818e9eda145d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.004831094429155668\n",
      "step: 50000 loss: 0.004313376732170582\n",
      "step: 50200 loss: 0.004688977729529142\n",
      "step: 50400 loss: 0.005839629098773003\n",
      "step: 50600 loss: 0.004835675936192274\n",
      "step: 50800 loss: 0.005160741042345762\n",
      "step: 51000 loss: 0.004102484788745642\n",
      "step: 51200 loss: 0.005151880439370871\n",
      "step: 51400 loss: 0.004015315789729357\n",
      "step: 51600 loss: 0.0031323526054620743\n",
      "step: 51800 loss: 0.003652641549706459\n",
      "step: 52000 loss: 0.005571655463427305\n",
      "step: 52200 loss: 0.004910406656563282\n",
      "step: 52400 loss: 0.0049752127379179\n",
      "step: 52600 loss: 0.004263041540980339\n",
      "step: 52800 loss: 0.005450797732919455\n",
      "step: 53000 loss: 0.0041834949515759945\n",
      "step: 53200 loss: 0.0061322348192334175\n",
      "step: 53400 loss: 0.004951458889991045\n",
      "step: 53600 loss: 0.004839623346924782\n",
      "step: 53800 loss: 0.004623217508196831\n",
      "step: 54000 loss: 0.007104769814759493\n",
      "step: 54200 loss: 0.003943278919905424\n",
      "step: 54400 loss: 0.005263890605419874\n",
      "step: 54600 loss: 0.0047859870828688145\n",
      "step: 54800 loss: 0.005421469919383526\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57c06ded2184aa692baee6df2f0ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.004786799380395019\n",
      "step: 55000 loss: 0.004281916189938784\n",
      "step: 55200 loss: 0.004682584665715694\n",
      "step: 55400 loss: 0.005313456058502197\n",
      "step: 55600 loss: 0.00568461325019598\n",
      "step: 55800 loss: 0.004198024515062571\n",
      "step: 56000 loss: 0.005564683582633734\n",
      "step: 56200 loss: 0.004909052513539791\n",
      "step: 56400 loss: 0.004340255167335272\n",
      "step: 56600 loss: 0.005233125761151314\n",
      "step: 56800 loss: 0.005554497241973877\n",
      "step: 57000 loss: 0.004464512690901756\n",
      "step: 57200 loss: 0.004200706258416176\n",
      "step: 57400 loss: 0.00333963381126523\n",
      "step: 57600 loss: 0.004042338114231825\n",
      "step: 57800 loss: 0.0035102758556604385\n",
      "step: 58000 loss: 0.005341269541531801\n",
      "step: 58200 loss: 0.0037936479784548283\n",
      "step: 58400 loss: 0.00474276440218091\n",
      "step: 58600 loss: 0.005074033979326487\n",
      "step: 58800 loss: 0.003639831906184554\n",
      "step: 59000 loss: 0.004549422767013311\n",
      "step: 59200 loss: 0.005566252861171961\n",
      "step: 59400 loss: 0.004764218349009752\n",
      "step: 59600 loss: 0.0042147389613091946\n",
      "step: 59800 loss: 0.0057709114626049995\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf82008dcd044166b475cf65e3319f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.004777440300121256\n",
      "step: 60000 loss: 0.006069455295801163\n",
      "step: 60200 loss: 0.00526946596801281\n",
      "step: 60400 loss: 0.00422582495957613\n",
      "step: 60600 loss: 0.005483999382704496\n",
      "step: 60800 loss: 0.0050404430367052555\n",
      "step: 61000 loss: 0.004714380484074354\n",
      "step: 61200 loss: 0.007539224810898304\n",
      "step: 61400 loss: 0.004355337470769882\n",
      "step: 61600 loss: 0.004614986479282379\n",
      "step: 61800 loss: 0.003914312459528446\n",
      "step: 62000 loss: 0.005472263321280479\n",
      "step: 62200 loss: 0.0037036275025457144\n",
      "step: 62400 loss: 0.005551773123443127\n",
      "step: 62600 loss: 0.005782519467175007\n",
      "step: 62800 loss: 0.003914413973689079\n",
      "step: 63000 loss: 0.005111378617584705\n",
      "step: 63200 loss: 0.00584035087376833\n",
      "step: 63400 loss: 0.005093981046229601\n",
      "step: 63600 loss: 0.0047060418874025345\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "now=time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "train_loss = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model/Classfication_abstract_model2022-04-23 01:39:03.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_395/4291698556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "valid_loss,total_preds,total_labels = evaluate(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc,precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs#[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    precision = precision_score(y_true,y_pred)\n",
    "    print(f'Precision: {precision*100:.2f}%')\n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# function for evaluating the model\n",
    "def evaluate(mydataloader):\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "    #t0 = time.time()\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in tqdm(enumerate(mydataloader),total=len(mydataloader)):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)   \n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            loss, outputs = model(input_ids, attention_mask, labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            total_preds.append(outputs)\n",
    "            total_labels.append(labels)\n",
    "\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    print(f\"{step}: {avg_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    total_labels = np.concatenate(total_labels, axis=0)\n",
    "    true = np.array(total_labels)\n",
    "    pred = np.array(total_preds>0.5)\n",
    "    #print(true)\n",
    "    #print(pred)\n",
    "    for i, name in enumerate(LABEL_COLUMNS):\n",
    "        try:\n",
    "            print(f\"{name} roc_auc {roc_auc_score(true[:, i], pred[:, i])}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    print(f\"Evaluate loss {total_loss / len(val_dataloader)}\")\n",
    "    \n",
    "    \n",
    "    total_patent=0\n",
    "    acc_patent=0\n",
    "    for pp,pr in zip(pred,true):\n",
    "        total_patent+=1\n",
    "        if all(pp==pr):\n",
    "            acc_patent+=1\n",
    "    print(f\"Predict accuracy num: {acc_patent},total Patent num: {total_patent}, Accuracy: {acc_patent/total_patent*100:.2f}%\")\n",
    "    \n",
    "    return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score)\n",
    "\n",
    "\n",
    "true = np.array(total_labels)\n",
    "pred = np.array(total_preds>0.5)\n",
    "\n",
    "dic = {\n",
    "    \"Accuracy\" : accuracy_score(true,pred),\n",
    "    \"Precision-micro\" : precision_score(true,pred,average='micro'),\n",
    "    \"Precision-macro\" : precision_score(true,pred,average='macro'),\n",
    "    \"recall-micro\" : recall_score(true,pred,average='micro'),\n",
    "    \"recall-macro\" : recall_score(true,pred,average='macro'),\n",
    "    \"f1_micro\" : f1_score(true,pred,average='micro'),\n",
    "    \"f1-macro\" : f1_score(true,pred,average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3850360576923077,\n",
       " 'Precision-micro': 0.8007889877455094,\n",
       " 'Precision-macro': 0.48546576079778736,\n",
       " 'recall-micro': 0.5182517436933707,\n",
       " 'recall-macro': 0.2494437992538163,\n",
       " 'f1_micro': 0.6292607640354579,\n",
       " 'f1-macro': 0.31188530500687855}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test scores \n",
    "# learning rate 5e-5\n",
    "# batch_size 32\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3974908200734394,\n",
       " 'Precision-micro': 0.8567705276010238,\n",
       " 'Precision-macro': 0.3543756250077216,\n",
       " 'recall-micro': 0.42521033863938285,\n",
       " 'recall-macro': 0.1348312852097599,\n",
       " 'f1_micro': 0.5683512067475059,\n",
       " 'f1-macro': 0.18028400221502028}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation scores\n",
    "# learning_rate 5e-5\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.34275610207100593,\n",
       " 'Precision-micro': 0.8686674889223882,\n",
       " 'Precision-macro': 0.37088179823084866,\n",
       " 'recall-micro': 0.3982942216338944,\n",
       " 'recall-macro': 0.1260824985554961,\n",
       " 'f1_micro': 0.5461652684154142,\n",
       " 'f1-macro': 0.17231818742954721}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2021-A scores\n",
    "# learning_rate 5e-5\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3426790557199211,\n",
       " 'Precision-micro': 0.8687377221435424,\n",
       " 'Precision-macro': 0.3707975747138592,\n",
       " 'recall-micro': 0.3982917010518731,\n",
       " 'recall-macro': 0.1260669178061862,\n",
       " 'f1_micro': 0.5461767797749323,\n",
       " 'f1-macro': 0.17230378630870097}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2021-A scores\n",
    "# learning_rate 5e-5\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3416666666666667,\n",
       " 'Precision-micro': 0.8671591098021518,\n",
       " 'Precision-macro': 0.3461082396608983,\n",
       " 'recall-micro': 0.3967615735709628,\n",
       " 'recall-macro': 0.12544875490870652,\n",
       " 'f1_micro': 0.5444256391521215,\n",
       " 'f1-macro': 0.17069473713464509}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2021-A-50000 scores\n",
    "# learning_rate 5e-5\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./baseline-Classification-USPTO-2M{now}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2021-A\n",
    "test_df = pd.read_feather(\"./autodl-nas/2021-sample-50000.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PatentDataset(\n",
    "  test_df,\n",
    "  tokenizer,\n",
    "  max_token_len=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=8*BATCH_SIZE, shuffle=True,drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e18a2fb164b30900732d27b87319a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate loss 0.005401214983505316\n"
     ]
    }
   ],
   "source": [
    "avg_loss, total_preds, total_labels = evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79449e242eb04b4b817eae1ad2b28422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate loss 0.005900688882535084\n"
     ]
    }
   ],
   "source": [
    "avg_loss, total_preds, total_labels = evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "164dc99c25814f6ab80b1620d5bbdccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_5445e44543df4f0593767b43681f48f0",
       "max": 86055,
       "style": "IPY_MODEL_ccb7249e92c14924821f89b126e0cacd",
       "value": 85982
      }
     },
     "1d50adeb23e542a5aa98f7de96d6a9d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1e895d0af15b4ff2a6c2ad14a91f5748": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_c903ce8ed8c54437b67158c54da3a22a",
       "max": 10757,
       "style": "IPY_MODEL_f8a513de577440318b252bef4f2da141",
       "value": 9544
      }
     },
     "20a637e61a934dc3a1c79ed24c7cecd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6ec90b1f56454be6b23a9bbfc75ffcf1",
       "style": "IPY_MODEL_6d5cbecbab2a45b28710fe24e4ac6de6",
       "value": " 85982/86055 [11:24:22&lt;00:35,  2.06it/s]"
      }
     },
     "2748d0831de24a3288e63ff82496a7d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_90cfa066ef354ea2b1ee38ef9a5f8099",
       "max": 5,
       "style": "IPY_MODEL_593f5fe9c83d4b85a4fbd9fd447b8e9a"
      }
     },
     "2b90dffa457c429f99c92d510b048761": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "309c7152a11d4c1381a88e9c451751c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "37e133be36cf4b31a6e83448ade7534b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_728b2a6ea0f0465282eb7464e28b8f85",
       "max": 86055,
       "style": "IPY_MODEL_1d50adeb23e542a5aa98f7de96d6a9d7",
       "value": 44175
      }
     },
     "3896630326114e08b072c857b038bc1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a7d8d6da3f54f238b0afea6e7ee2b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a467379af6fb4610af04419257bcd97e",
       "style": "IPY_MODEL_2b90dffa457c429f99c92d510b048761",
       "value": "Eval:  89%"
      }
     },
     "3ae8ae0bda93481196c4f129a01bf000": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f50ae3f29d31451f941bca0d4a03a215",
       "style": "IPY_MODEL_8ee2175173904a2eb2d9aba4753e15d6",
       "value": " 44175/86055 [5:52:16&lt;4:55:35,  2.36it/s]"
      }
     },
     "4314a58991154b8e862b9b2e0aebef2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f12a82db3205424182376a8b167778d1",
        "IPY_MODEL_37e133be36cf4b31a6e83448ade7534b",
        "IPY_MODEL_3ae8ae0bda93481196c4f129a01bf000"
       ],
       "layout": "IPY_MODEL_3896630326114e08b072c857b038bc1a"
      }
     },
     "434444785a7e447e87e0cad98313ad1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5445e44543df4f0593767b43681f48f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "556f902dd03b49fbb6bf7120e444631e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "573e3df279c94dcdbcca6d4fbc2baba5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "593f5fe9c83d4b85a4fbd9fd447b8e9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6c8675f1019348b090dcfd9a695e28ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6d5cbecbab2a45b28710fe24e4ac6de6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6ec90b1f56454be6b23a9bbfc75ffcf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ef42ab2cf214b2a9c161320cab5eaf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e5da622f865b4be589d33d9bf11bff95",
       "style": "IPY_MODEL_309c7152a11d4c1381a88e9c451751c9",
       "value": "  0%"
      }
     },
     "728b2a6ea0f0465282eb7464e28b8f85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8ee2175173904a2eb2d9aba4753e15d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "90cfa066ef354ea2b1ee38ef9a5f8099": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9820aa3240884437b73ec6ac97f9bfeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a7a893bdc5b4996bb0af662499a1031": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3a7d8d6da3f54f238b0afea6e7ee2b85",
        "IPY_MODEL_1e895d0af15b4ff2a6c2ad14a91f5748",
        "IPY_MODEL_d8a58dc7a14847c380437b483941f7b8"
       ],
       "layout": "IPY_MODEL_bb728dc1babb44c59b277d6c0fae77d1"
      }
     },
     "9acb681f98d74355b0d50fd3392c7ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3685fa7e19d4cc78a84fe0f9a47d392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a467379af6fb4610af04419257bcd97e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad8d9ad1431f4ab2961b70feb3bffef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb728dc1babb44c59b277d6c0fae77d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0bbf35d93224082a7f0abddb98cecf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c15c1985d6914f08b96560a7231ee0ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3685fa7e19d4cc78a84fe0f9a47d392",
       "style": "IPY_MODEL_434444785a7e447e87e0cad98313ad1f",
       "value": " 0/5 [00:00&lt;?, ?it/s]"
      }
     },
     "c903ce8ed8c54437b67158c54da3a22a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ccb7249e92c14924821f89b126e0cacd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d5e99427fc1a466589e96bf94e2e0b89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6ef42ab2cf214b2a9c161320cab5eaf4",
        "IPY_MODEL_2748d0831de24a3288e63ff82496a7d9",
        "IPY_MODEL_c15c1985d6914f08b96560a7231ee0ae"
       ],
       "layout": "IPY_MODEL_c0bbf35d93224082a7f0abddb98cecf8"
      }
     },
     "d8a58dc7a14847c380437b483941f7b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ad8d9ad1431f4ab2961b70feb3bffef4",
       "style": "IPY_MODEL_f1587b8254aa4fe995d0262ff5c0ff0d",
       "value": " 9544/10757 [25:20&lt;03:20,  6.06it/s]"
      }
     },
     "e5da622f865b4be589d33d9bf11bff95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6911c72c9fb4701bf09e05c358cc971": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f16d3926bf7d42f3a864c8aaf75d8fa2",
        "IPY_MODEL_164dc99c25814f6ab80b1620d5bbdccb",
        "IPY_MODEL_20a637e61a934dc3a1c79ed24c7cecd1"
       ],
       "layout": "IPY_MODEL_573e3df279c94dcdbcca6d4fbc2baba5"
      }
     },
     "f12a82db3205424182376a8b167778d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9820aa3240884437b73ec6ac97f9bfeb",
       "style": "IPY_MODEL_6c8675f1019348b090dcfd9a695e28ca",
       "value": "Train:  49%"
      }
     },
     "f1587b8254aa4fe995d0262ff5c0ff0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f16d3926bf7d42f3a864c8aaf75d8fa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9acb681f98d74355b0d50fd3392c7ec2",
       "style": "IPY_MODEL_556f902dd03b49fbb6bf7120e444631e",
       "value": "Train: 100%"
      }
     },
     "f50ae3f29d31451f941bca0d4a03a215": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f8a513de577440318b252bef4f2da141": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
