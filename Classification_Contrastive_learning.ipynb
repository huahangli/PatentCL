{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 28 18:16:00 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.54       Driver Version: 510.54       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   32C    P0    76W / 300W |   9409MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A40          On   | 00000000:23:00.0 Off |                  Off |\n",
      "|  0%   31C    P0    76W / 300W |      2MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    959040      C                                    9407MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import os\n",
    "\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "EPOCHS = 1\n",
    "MAX_TOKEN_COUNT = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 s, sys: 1min 57s, total: 2min 27s\n",
      "Wall time: 45.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['A41D', 'A62B', 'A41B', 'D06N', 'A42B', 'A43B', 'D06B', 'A41F', 'E03D',\n",
       "       'A47K',\n",
       "       ...\n",
       "       'Y02D', 'F24V', 'H04T', 'G16B', 'G16C', 'G16Z', 'G21J', 'G16Y', 'G06J',\n",
       "       'E99Z'],\n",
       "      dtype='object', length=664)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "train_df=pd.read_feather(\"./autodl-nas/USPTO-2M_Training.feather\")\n",
    "val_df=pd.read_feather(\"./autodl-nas/USPTO-2M_Validation.feather\")\n",
    "\n",
    "LABEL_COLUMNS=train_df.columns[11:]\n",
    "LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pass pandas dataframe, and tokeizer along with the max token length[128 default]\n",
    "    \n",
    "    Example: \n",
    "    -------\n",
    "    train_dataset = ToxicCommentsDataset(\n",
    "      train_df,\n",
    "      tokenizer,\n",
    "      max_token_len=MAX_TOKEN_COUNT\n",
    "    )\n",
    "\n",
    "    sample_item = train_dataset[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: BertTokenizer,\n",
    "        max_token_len: int = 512,\n",
    "        test= False\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "        self.test = test\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "#         comment_text = \"\".join(data_row.claims)\n",
    "        comment_text = data_row.claims[0]\n",
    "\n",
    "        if not self.test:\n",
    "            labels = data_row[LABEL_COLUMNS]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            add_special_tokens=True, # [CLS] & [SEP]\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True, #attention_mask\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        if not self.test:\n",
    "            return dict(\n",
    "#             comment_text=comment_text,\n",
    "            input_ids = encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )\n",
    "        else:\n",
    "            return dict(\n",
    "#                 comment_text=comment_text,\n",
    "                input_ids = encoding[\"input_ids\"].flatten(),\n",
    "                attention_mask=encoding[\"attention_mask\"].flatten()\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PatentDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=128\n",
    ")\n",
    "\n",
    "val_dataset = PatentDataset(\n",
    "  val_df,\n",
    "  tokenizer,\n",
    "  max_token_len=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,drop_last = True,pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last = True,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive learning loss funcation\n",
    "\n",
    "class ConLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, temperature = 0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, embeddings, labels):\n",
    "       \n",
    "        # embeddings (batch_size,bert_hidden_layer) , labels (batch_size,num_classes)\n",
    "        similarities = F.cosine_similarity(embeddings.unsqueeze(1),embeddings.unsqueeze(0),dim=2)/self.temperature\n",
    "#         print(similarities)\n",
    "        \n",
    "        # mask\n",
    "        logits_mask = ~torch.eye(BATCH_SIZE,dtype=torch.bool).to(device)\n",
    "        labels_mask = ~torch.eye(BATCH_SIZE,dtype=torch.bool).to(device)\n",
    "\n",
    "        exp_logits = torch.exp(similarities) * logits_mask\n",
    "        loss = torch.log(exp_logits.sum(1,keepdim=True)) - similarities\n",
    "        \n",
    "        # labels \n",
    "        weight = torch.matmul(labels,labels.T)\n",
    "        # weight = weight - torch.diag_embed(torch.diag(weight))\n",
    "        # total_weight = torch.sum(weight,dim=1,keepdim=True)\n",
    "        # weight = torch.where(total_weight!=0,weight/total_weight,weight)\n",
    "        \n",
    "        weight = weight / torch.diag(weight)\n",
    "        weight = weight * labels_mask\n",
    "        weight = torch.where(weight!=1,torch.zeros_like(weight).to(device),weight)\n",
    "        weight = weight/torch.sum(weight)\n",
    "#         print(weight)\n",
    "        \n",
    "        loss = weight * loss\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True) #load the pretrained bert model\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = output.last_hidden_state[:,0]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes: int ):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Linear(768,n_classes)\n",
    "        self.dropout = nn.Dropout(0.10)\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,embeddings,labels = None):\n",
    "        \n",
    "        output = self.classifier(self.dropout(embeddings))\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output,labels)\n",
    "            output = (loss,output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3188, 31880)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertNetwork(len(LABEL_COLUMNS)).to(device)\n",
    "Conloss =  ConLoss().to(device)\n",
    "classifier = Classifier(len(LABEL_COLUMNS)).to(device)\n",
    "N_EPOCHS = EPOCHS\n",
    "\n",
    "steps_per_epoch=len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 10\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=2e-4)\n",
    "\n",
    "optimizer = AdamW([\n",
    "                {'params': model.parameters()},\n",
    "                {'params': classifier.parameters()}],\n",
    "                lr=2e-4\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate(mydataloader):\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "    #t0 = time.time()\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in tqdm(enumerate(mydataloader),total=len(mydataloader),desc='Eval'):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)   \n",
    "        # deactivate autograd\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss1 = Conloss(outputs,labels)\n",
    "                loss2,outputs = classifier(outputs,labels)\n",
    "                if step%500 ==0:\n",
    "                    print(f\"loss contrastive :{loss1}  loss classifier: {loss2}\")\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "\n",
    "                loss = loss2\n",
    "                total_loss = total_loss + loss.float().item()\n",
    "\n",
    "                outputs = outputs.detach().float().cpu().numpy()\n",
    "                labels = labels.detach().float().cpu().numpy()\n",
    "                total_preds.append(outputs)\n",
    "                total_labels.append(labels)\n",
    "\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(mydataloader)\n",
    "\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    total_labels = np.concatenate(total_labels, axis=0)\n",
    "    model.train()\n",
    "    print(f\"Evaluate loss {total_loss / len(mydataloader)}\")\n",
    "    return avg_loss, total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    now=time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "    best_valid_loss = float('inf')\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    avg_loss = 0\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    # iterate over batches\n",
    "    for step,batch in tqdm(enumerate(train_dataloader),total=len(train_dataloader),desc=\"Train\"):\n",
    "        \n",
    "        if step%1000 == 0 and step!=0:\n",
    "            valid_loss,_,_ = evaluate(val_dataloader)\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), f\"./model/Classfication_Contrastive_model{now}.pt\")\n",
    "                torch.save(classifier.state_dict(),f\"./model/Classfication_Contrastive_classifier{now}.pt\")\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)  \n",
    "        if step > 0.6*len(train_dataloader):\n",
    "            with autocast():\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss1 = Conloss(outputs,labels)\n",
    "                loss2,_ = classifier(outputs,labels)\n",
    "                loss = loss1 + loss2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if step%200 == 0:\n",
    "                print(f\"STEP {step}: loss contrastive :{loss1}  loss classifier: {loss2}\")\n",
    "        else:\n",
    "            with autocast():\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss,_ = classifier(outputs,labels)\n",
    "            optimizer.zero_grad()\n",
    "            if step%200 == 0:\n",
    "                print(f\"STEP {step}: loss classifier: {loss}\")\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        scaler.update()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        outputs=outputs.detach().float().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(outputs)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"{step}: {avg_loss}\")\n",
    "  \n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e62282c6c5406eb88a8181029fcb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/31880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss classifier: 0.7028471231460571\n",
      "STEP 200: loss classifier: 0.35217714309692383\n",
      "STEP 400: loss classifier: 0.1153893694281578\n",
      "STEP 600: loss classifier: 0.04613625630736351\n",
      "STEP 800: loss classifier: 0.026719212532043457\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965a99a2930f46ee8bc835bb79229473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0010096090845763683  loss classifier: 0.019642315804958344\n",
      "loss contrastive :0.0010098202619701624  loss classifier: 0.01739700883626938\n",
      "Evaluate loss 0.01907718942627183\n",
      "STEP 1000: loss classifier: 0.01976439729332924\n",
      "STEP 1200: loss classifier: 0.015366089530289173\n",
      "STEP 1400: loss classifier: 0.013122770935297012\n",
      "STEP 1600: loss classifier: 0.012950985692441463\n",
      "STEP 1800: loss classifier: 0.012010379694402218\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86246ffe27f144c5b79ba941f818694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008076670928858221  loss classifier: 0.012389399111270905\n",
      "loss contrastive :0.0008883739355951548  loss classifier: 0.009530974552035332\n",
      "Evaluate loss 0.011651771189815922\n",
      "STEP 2000: loss classifier: 0.010989558883011341\n",
      "STEP 2200: loss classifier: 0.011290882714092731\n",
      "STEP 2400: loss classifier: 0.010745418258011341\n",
      "STEP 2600: loss classifier: 0.010385711677372456\n",
      "STEP 2800: loss classifier: 0.009185759350657463\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b008a4b364eb18ad9b640d143783e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006974786520004272  loss classifier: 0.009389062412083149\n",
      "loss contrastive :0.0008503607241436839  loss classifier: 0.007089272607117891\n",
      "Evaluate loss 0.008739171581595881\n",
      "STEP 3000: loss classifier: 0.007758451160043478\n",
      "STEP 3200: loss classifier: 0.008060689084231853\n",
      "STEP 3400: loss classifier: 0.008534119464457035\n",
      "STEP 3600: loss classifier: 0.008640121668577194\n",
      "STEP 3800: loss classifier: 0.006333112251013517\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ebd046b36a4837b681f40d348e03d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006348930182866752  loss classifier: 0.007628263905644417\n",
      "loss contrastive :0.0008419989608228207  loss classifier: 0.006137077696621418\n",
      "Evaluate loss 0.007433349250119312\n",
      "STEP 4000: loss classifier: 0.007641992997378111\n",
      "STEP 4200: loss classifier: 0.007826059125363827\n",
      "STEP 4400: loss classifier: 0.008106736466288567\n",
      "STEP 4600: loss classifier: 0.009081295691430569\n",
      "STEP 4800: loss classifier: 0.00618650671094656\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38087efa3a964de29209856a471fa3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0005990357021801174  loss classifier: 0.0067250365391373634\n",
      "loss contrastive :0.0008330449927598238  loss classifier: 0.005329926498234272\n",
      "Evaluate loss 0.006668284212237947\n",
      "STEP 5000: loss classifier: 0.005910747218877077\n",
      "STEP 5200: loss classifier: 0.006799269001930952\n",
      "STEP 5400: loss classifier: 0.007793578319251537\n",
      "STEP 5600: loss classifier: 0.0063172997906804085\n",
      "STEP 5800: loss classifier: 0.005842671263962984\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7707655061443898f6d094ac0d7abdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006300364038906991  loss classifier: 0.006624117493629456\n",
      "loss contrastive :0.0008568608900532126  loss classifier: 0.005420580506324768\n",
      "Evaluate loss 0.006292590733806772\n",
      "STEP 6000: loss classifier: 0.0070038484409451485\n",
      "STEP 6200: loss classifier: 0.005457405932247639\n",
      "STEP 6400: loss classifier: 0.005658808629959822\n",
      "STEP 6600: loss classifier: 0.004498820751905441\n",
      "STEP 6800: loss classifier: 0.006967401597648859\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9f2c65a13c47d0b14906d53678bb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006373724900186062  loss classifier: 0.006469070445746183\n",
      "loss contrastive :0.0008489875472150743  loss classifier: 0.005214997101575136\n",
      "Evaluate loss 0.006104590747712893\n",
      "STEP 7000: loss classifier: 0.0062493570148944855\n",
      "STEP 7200: loss classifier: 0.00613329978659749\n",
      "STEP 7400: loss classifier: 0.003834730014204979\n",
      "STEP 7800: loss classifier: 0.004742268938571215\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520d8825b1474903ac919f4ede229320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006640902138315141  loss classifier: 0.006406976375728846\n",
      "loss contrastive :0.0008472061017528176  loss classifier: 0.004916551988571882\n",
      "Evaluate loss 0.005950634778993639\n",
      "STEP 8000: loss classifier: 0.007365568075329065\n",
      "STEP 8200: loss classifier: 0.0052322098053991795\n",
      "STEP 8400: loss classifier: 0.006184171885251999\n",
      "STEP 8600: loss classifier: 0.0063955881632864475\n",
      "STEP 8800: loss classifier: 0.0060486807487905025\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f07d566f5d8489980982061fa299967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006103534833528101  loss classifier: 0.005644454155117273\n",
      "loss contrastive :0.0008496025111526251  loss classifier: 0.004749954678118229\n",
      "Evaluate loss 0.005747179279327302\n",
      "STEP 9000: loss classifier: 0.005407894961535931\n",
      "STEP 9200: loss classifier: 0.007298095617443323\n",
      "STEP 9400: loss classifier: 0.005883070174604654\n",
      "STEP 9600: loss classifier: 0.00642632320523262\n",
      "STEP 9800: loss classifier: 0.0050896708853542805\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d9d9a3e8574b3fad933f1b497617da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006041912129148841  loss classifier: 0.005903243087232113\n",
      "loss contrastive :0.0008442456019110978  loss classifier: 0.004694532137364149\n",
      "Evaluate loss 0.0056615441255590615\n",
      "STEP 10000: loss classifier: 0.005143082235008478\n",
      "STEP 10200: loss classifier: 0.005611708387732506\n",
      "STEP 10400: loss classifier: 0.0063965641893446445\n",
      "STEP 10600: loss classifier: 0.005503572057932615\n",
      "STEP 10800: loss classifier: 0.003732773708179593\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12433e1539204de8bafe0903976e2e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006237812340259552  loss classifier: 0.005748061463236809\n",
      "loss contrastive :0.0008347185212187469  loss classifier: 0.004405277781188488\n",
      "Evaluate loss 0.005592836498258911\n",
      "STEP 11000: loss classifier: 0.005529221147298813\n",
      "STEP 11200: loss classifier: 0.005216518417000771\n",
      "STEP 11400: loss classifier: 0.006083405576646328\n",
      "STEP 11600: loss classifier: 0.006214025896042585\n",
      "STEP 11800: loss classifier: 0.004499891772866249\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6297aeee3cce427494d58ecadcf183f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006190416170284152  loss classifier: 0.0055509526282548904\n",
      "loss contrastive :0.0008533282089047134  loss classifier: 0.004647146910429001\n",
      "Evaluate loss 0.005495062562998389\n",
      "STEP 12000: loss classifier: 0.006479186937212944\n",
      "STEP 12200: loss classifier: 0.005418709479272366\n",
      "STEP 12400: loss classifier: 0.005767521448433399\n",
      "STEP 12600: loss classifier: 0.005843021906912327\n",
      "STEP 12800: loss classifier: 0.0045595793053507805\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f009e55eac5442b98c53a7d14363f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0006248630816116929  loss classifier: 0.005825744476169348\n",
      "loss contrastive :0.000848100520670414  loss classifier: 0.004322818946093321\n",
      "Evaluate loss 0.0054358031419464905\n",
      "STEP 13000: loss classifier: 0.004877395462244749\n",
      "STEP 13200: loss classifier: 0.0053174979984760284\n"
     ]
    }
   ],
   "source": [
    "train_loss, _ = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50942b0908f04475849a6ddc8ccc07f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c7e8d7c91475f80c5e283e267b34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0010610689641907811  loss classifier: 0.6774331331253052\n",
      "STEP 50: loss contrastive :0.0010139003861695528  loss classifier: 0.38425585627555847\n",
      "STEP 100: loss contrastive :0.0009989901445806026  loss classifier: 0.3425288498401642\n",
      "STEP 150: loss contrastive :0.0009738221997395158  loss classifier: 0.312829852104187\n",
      "STEP 200: loss contrastive :0.0009476971463300288  loss classifier: 0.2964755892753601\n",
      "STEP 250: loss contrastive :0.0009283071267418563  loss classifier: 0.29871895909309387\n",
      "STEP 300: loss contrastive :0.0009683565585874021  loss classifier: 0.29144302010536194\n",
      "STEP 350: loss contrastive :0.0009231276926584542  loss classifier: 0.268029123544693\n",
      "STEP 400: loss contrastive :0.0009250261355191469  loss classifier: 0.27633774280548096\n",
      "STEP 450: loss contrastive :0.0009329313761554658  loss classifier: 0.292875736951828\n",
      "STEP 500: loss contrastive :0.0009649590938352048  loss classifier: 0.28385740518569946\n",
      "STEP 550: loss contrastive :0.000941928185056895  loss classifier: 0.2630852460861206\n",
      "STEP 600: loss contrastive :0.0008871428435668349  loss classifier: 0.26286780834198\n",
      "STEP 650: loss contrastive :0.0009311708272434771  loss classifier: 0.24646306037902832\n",
      "STEP 700: loss contrastive :0.0009406199678778648  loss classifier: 0.27898043394088745\n",
      "STEP 750: loss contrastive :0.000936273077968508  loss classifier: 0.2600308954715729\n",
      "STEP 800: loss contrastive :0.0009399568662047386  loss classifier: 0.2894088625907898\n",
      "STEP 850: loss contrastive :0.0009553144918754697  loss classifier: 0.24985231459140778\n",
      "STEP 900: loss contrastive :0.0009723578114062548  loss classifier: 0.2619337737560272\n",
      "STEP 950: loss contrastive :0.0009201912907883525  loss classifier: 0.2603614926338196\n",
      "STEP 1000: loss contrastive :0.0009279796504415572  loss classifier: 0.2986651062965393\n",
      "STEP 1050: loss contrastive :0.0009358207462355494  loss classifier: 0.2539086937904358\n",
      "STEP 1100: loss contrastive :0.0009451773366890848  loss classifier: 0.2548912763595581\n",
      "STEP 1150: loss contrastive :0.0008927385206334293  loss classifier: 0.25713878870010376\n",
      "STEP 1200: loss contrastive :0.0009222639491781592  loss classifier: 0.2555825412273407\n",
      "STEP 1250: loss contrastive :0.0009245303808711469  loss classifier: 0.23886622488498688\n",
      "STEP 1300: loss contrastive :0.0009245075052604079  loss classifier: 0.24136416614055634\n",
      "\n",
      "1334: 0.28489712053693633\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0365cee28b3747578d0294eddf8555b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008807076374068856  loss classifier: 0.21857139468193054\n",
      "loss contrastive :0.0009065266931429505  loss classifier: 0.23401078581809998\n",
      "loss contrastive :0.0009554822463542223  loss classifier: 0.24336905777454376\n",
      "loss contrastive :0.0009160935296677053  loss classifier: 0.24640393257141113\n",
      "loss contrastive :0.0009338076924905181  loss classifier: 0.25457191467285156\n",
      "loss contrastive :0.0009518761653453112  loss classifier: 0.24289177358150482\n",
      "loss contrastive :0.0009178954060189426  loss classifier: 0.21809642016887665\n",
      "\n",
      "Evaluate loss 0.239400030033929\n",
      "\n",
      " Epoch 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c444f1e5434994a73ab213eca777b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0009442084701731801  loss classifier: 0.2308642864227295\n",
      "STEP 50: loss contrastive :0.0009086896316148341  loss classifier: 0.24797853827476501\n",
      "STEP 100: loss contrastive :0.0008787601254880428  loss classifier: 0.24488425254821777\n",
      "STEP 150: loss contrastive :0.0009530895622447133  loss classifier: 0.2338808923959732\n",
      "STEP 200: loss contrastive :0.000961251906119287  loss classifier: 0.2411338984966278\n",
      "STEP 250: loss contrastive :0.000928273017052561  loss classifier: 0.2574857175350189\n",
      "STEP 300: loss contrastive :0.0008967827307060361  loss classifier: 0.2313375324010849\n",
      "STEP 350: loss contrastive :0.000887261179741472  loss classifier: 0.2302122563123703\n",
      "STEP 400: loss contrastive :0.0009499300504103303  loss classifier: 0.23939299583435059\n",
      "STEP 450: loss contrastive :0.0009526830399408937  loss classifier: 0.24924124777317047\n",
      "STEP 500: loss contrastive :0.0009005170431919396  loss classifier: 0.23633794486522675\n",
      "STEP 550: loss contrastive :0.0008917097002267838  loss classifier: 0.2255229502916336\n",
      "STEP 600: loss contrastive :0.0008761959616094828  loss classifier: 0.22579538822174072\n",
      "STEP 650: loss contrastive :0.0009193914011120796  loss classifier: 0.22465437650680542\n",
      "STEP 700: loss contrastive :0.0009096328285522759  loss classifier: 0.2146378457546234\n",
      "STEP 750: loss contrastive :0.000901732943020761  loss classifier: 0.2276478260755539\n",
      "STEP 800: loss contrastive :0.000923407613299787  loss classifier: 0.22784242033958435\n",
      "STEP 850: loss contrastive :0.0009010914945974946  loss classifier: 0.2391776144504547\n",
      "STEP 900: loss contrastive :0.000927389191929251  loss classifier: 0.21868760883808136\n",
      "STEP 950: loss contrastive :0.0009482597233727574  loss classifier: 0.2268771231174469\n",
      "STEP 1000: loss contrastive :0.0009044851758517325  loss classifier: 0.23813016712665558\n",
      "STEP 1050: loss contrastive :0.0009156233281828463  loss classifier: 0.24004775285720825\n",
      "STEP 1100: loss contrastive :0.0009272374445572495  loss classifier: 0.23553557693958282\n",
      "STEP 1150: loss contrastive :0.0009110203827731311  loss classifier: 0.2299789935350418\n",
      "STEP 1200: loss contrastive :0.0008783993544057012  loss classifier: 0.21437770128250122\n",
      "STEP 1250: loss contrastive :0.000897350546438247  loss classifier: 0.2281295657157898\n",
      "STEP 1300: loss contrastive :0.0009208637056872249  loss classifier: 0.2311241328716278\n",
      "\n",
      "1334: 0.23070132303773688\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0783c7864bc4ce080e785b6c3269491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008893839549273252  loss classifier: 0.20146054029464722\n",
      "loss contrastive :0.0008835346670821309  loss classifier: 0.2135966420173645\n",
      "loss contrastive :0.0009539992897771299  loss classifier: 0.22898778319358826\n",
      "loss contrastive :0.0008915557991713285  loss classifier: 0.2200794667005539\n",
      "loss contrastive :0.0009340487304143608  loss classifier: 0.23876436054706573\n",
      "loss contrastive :0.0009146474185399711  loss classifier: 0.22410865128040314\n",
      "loss contrastive :0.0009144307114183903  loss classifier: 0.20079663395881653\n",
      "\n",
      "Evaluate loss 0.224818488742624\n",
      "\n",
      " Epoch 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f5cb9bb826451e88a8d01498e0c17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0008946646121330559  loss classifier: 0.215729758143425\n",
      "STEP 50: loss contrastive :0.000933293136768043  loss classifier: 0.21107187867164612\n",
      "STEP 100: loss contrastive :0.0009095509303733706  loss classifier: 0.20472170412540436\n",
      "STEP 150: loss contrastive :0.0008889230666682124  loss classifier: 0.2009972184896469\n",
      "STEP 200: loss contrastive :0.000898425467312336  loss classifier: 0.220720112323761\n",
      "STEP 250: loss contrastive :0.0008432338945567608  loss classifier: 0.19577822089195251\n",
      "STEP 300: loss contrastive :0.0009300133096985519  loss classifier: 0.20456856489181519\n",
      "STEP 350: loss contrastive :0.0009636440081521869  loss classifier: 0.21720096468925476\n",
      "STEP 400: loss contrastive :0.0009122542687691748  loss classifier: 0.21185627579689026\n",
      "STEP 450: loss contrastive :0.0009121580515056849  loss classifier: 0.2047554850578308\n",
      "STEP 500: loss contrastive :0.0009195298771373928  loss classifier: 0.19961179792881012\n",
      "STEP 550: loss contrastive :0.0009489330695942044  loss classifier: 0.22855181992053986\n",
      "STEP 600: loss contrastive :0.0009001567377708852  loss classifier: 0.2121484875679016\n",
      "STEP 650: loss contrastive :0.0009109622915275395  loss classifier: 0.23586995899677277\n",
      "STEP 700: loss contrastive :0.0008985733147710562  loss classifier: 0.20237237215042114\n",
      "STEP 750: loss contrastive :0.0008942872518673539  loss classifier: 0.19298163056373596\n",
      "STEP 800: loss contrastive :0.0008995592361316085  loss classifier: 0.2190903127193451\n",
      "STEP 850: loss contrastive :0.000899295904673636  loss classifier: 0.19127169251441956\n",
      "STEP 900: loss contrastive :0.0008805564721114933  loss classifier: 0.19340704381465912\n",
      "STEP 950: loss contrastive :0.0009056915296241641  loss classifier: 0.21813267469406128\n",
      "STEP 1000: loss contrastive :0.0008682067273184657  loss classifier: 0.2132941633462906\n",
      "STEP 1050: loss contrastive :0.0008939316030591726  loss classifier: 0.17876087129116058\n",
      "STEP 1100: loss contrastive :0.0009004317107610404  loss classifier: 0.2173953354358673\n",
      "STEP 1150: loss contrastive :0.0009163804352283478  loss classifier: 0.20730827748775482\n",
      "STEP 1200: loss contrastive :0.0009063553297892213  loss classifier: 0.187158465385437\n",
      "STEP 1250: loss contrastive :0.0009123301133513451  loss classifier: 0.1970745474100113\n",
      "STEP 1300: loss contrastive :0.0008618412539362907  loss classifier: 0.19862429797649384\n",
      "\n",
      "1334: 0.2060488157727745\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7792f004dd134b61a5f50a0064e33fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008923079585656524  loss classifier: 0.2057870328426361\n",
      "loss contrastive :0.0008866586722433567  loss classifier: 0.21777421236038208\n",
      "loss contrastive :0.0009292339673265815  loss classifier: 0.218560591340065\n",
      "loss contrastive :0.0008858245564624667  loss classifier: 0.2149192988872528\n",
      "loss contrastive :0.0009333193302154541  loss classifier: 0.24170167744159698\n",
      "loss contrastive :0.0009262507664971054  loss classifier: 0.21084506809711456\n",
      "loss contrastive :0.0009197652107104659  loss classifier: 0.18989942967891693\n",
      "\n",
      "Evaluate loss 0.22155216634273528\n",
      "\n",
      " Epoch 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d11340fdfcd4fe0aa969caa59b20ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0009148622630164027  loss classifier: 0.18414299190044403\n",
      "STEP 50: loss contrastive :0.000876838224940002  loss classifier: 0.16890180110931396\n",
      "STEP 100: loss contrastive :0.0008993896190077066  loss classifier: 0.16637739539146423\n",
      "STEP 150: loss contrastive :0.0009161243215203285  loss classifier: 0.1544165462255478\n",
      "STEP 200: loss contrastive :0.0008454859489575028  loss classifier: 0.19036753475666046\n",
      "STEP 250: loss contrastive :0.0008776029571890831  loss classifier: 0.17521975934505463\n",
      "STEP 300: loss contrastive :0.000863123219460249  loss classifier: 0.15643495321273804\n",
      "STEP 350: loss contrastive :0.0008465180872008204  loss classifier: 0.17740429937839508\n",
      "STEP 400: loss contrastive :0.0008260203758254647  loss classifier: 0.17282404005527496\n",
      "STEP 450: loss contrastive :0.0008817882044240832  loss classifier: 0.18425744771957397\n",
      "STEP 500: loss contrastive :0.0008810520521365106  loss classifier: 0.17513351142406464\n",
      "STEP 550: loss contrastive :0.0008323629735969007  loss classifier: 0.17659255862236023\n",
      "STEP 600: loss contrastive :0.0008939534891396761  loss classifier: 0.1733613759279251\n",
      "STEP 650: loss contrastive :0.0009149214019998908  loss classifier: 0.18991927802562714\n",
      "STEP 700: loss contrastive :0.0009140722686424851  loss classifier: 0.17144525051116943\n",
      "STEP 750: loss contrastive :0.0008822049712762237  loss classifier: 0.1800699084997177\n",
      "STEP 800: loss contrastive :0.0008755988092161715  loss classifier: 0.18652907013893127\n",
      "STEP 850: loss contrastive :0.0008660417515784502  loss classifier: 0.16443268954753876\n",
      "STEP 1150: loss contrastive :0.0008580789435654879  loss classifier: 0.18766213953495026\n",
      "STEP 1200: loss contrastive :0.0008628497598692775  loss classifier: 0.1909981667995453\n",
      "STEP 1250: loss contrastive :0.0008643883047625422  loss classifier: 0.1847379058599472\n",
      "STEP 1300: loss contrastive :0.0009039732394739985  loss classifier: 0.17725397646427155\n",
      "\n",
      "1334: 0.17716465605778642\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b85f27d5bb84cfb92817115be50fbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.000891766743734479  loss classifier: 0.20928114652633667\n",
      "loss contrastive :0.0008764481754042208  loss classifier: 0.2221929430961609\n",
      "loss contrastive :0.0009337436640635133  loss classifier: 0.22371983528137207\n",
      "loss contrastive :0.0008815022883936763  loss classifier: 0.21296896040439606\n",
      "loss contrastive :0.0009235467296093702  loss classifier: 0.2502913475036621\n",
      "loss contrastive :0.000922387174796313  loss classifier: 0.22078891098499298\n",
      "loss contrastive :0.000905571854673326  loss classifier: 0.1916544884443283\n",
      "\n",
      "Evaluate loss 0.2295128060238702\n",
      "\n",
      " Epoch 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e8451c1ed44481a879241e817b41d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0008306929375976324  loss classifier: 0.15690772235393524\n",
      "STEP 50: loss contrastive :0.0008291496778838336  loss classifier: 0.15071210265159607\n",
      "STEP 100: loss contrastive :0.0008183603640645742  loss classifier: 0.1562301069498062\n",
      "STEP 150: loss contrastive :0.0008440852398052812  loss classifier: 0.14083687961101532\n",
      "STEP 200: loss contrastive :0.000838672393001616  loss classifier: 0.1721179187297821\n",
      "STEP 250: loss contrastive :0.0008693318231962621  loss classifier: 0.15354199707508087\n",
      "STEP 300: loss contrastive :0.0008761153439991176  loss classifier: 0.1530335247516632\n",
      "STEP 350: loss contrastive :0.0007590079912915826  loss classifier: 0.12554311752319336\n",
      "STEP 400: loss contrastive :0.0008974550291895866  loss classifier: 0.15950292348861694\n",
      "STEP 450: loss contrastive :0.0008219852461479604  loss classifier: 0.17826594412326813\n",
      "STEP 500: loss contrastive :0.0008417931385338306  loss classifier: 0.14752903580665588\n",
      "STEP 550: loss contrastive :0.0008218636503443122  loss classifier: 0.16200672090053558\n",
      "STEP 600: loss contrastive :0.0008211528765968978  loss classifier: 0.13816477358341217\n",
      "STEP 650: loss contrastive :0.0008447055006399751  loss classifier: 0.16482867300510406\n",
      "STEP 700: loss contrastive :0.0008477813680656254  loss classifier: 0.1468813568353653\n",
      "STEP 750: loss contrastive :0.0008151968941092491  loss classifier: 0.12947943806648254\n",
      "STEP 800: loss contrastive :0.0008598427521064878  loss classifier: 0.13776153326034546\n",
      "STEP 850: loss contrastive :0.0008039619424380362  loss classifier: 0.14150801301002502\n",
      "STEP 900: loss contrastive :0.0007994532352313399  loss classifier: 0.14632833003997803\n",
      "STEP 950: loss contrastive :0.0007750615477561951  loss classifier: 0.1424008458852768\n",
      "STEP 1000: loss contrastive :0.0008294120198115706  loss classifier: 0.14283975958824158\n",
      "STEP 1050: loss contrastive :0.0008441192330792546  loss classifier: 0.12468162178993225\n",
      "STEP 1100: loss contrastive :0.0008190621738322079  loss classifier: 0.1525908261537552\n",
      "STEP 1150: loss contrastive :0.0008136738324537873  loss classifier: 0.15397946536540985\n",
      "STEP 1200: loss contrastive :0.0008062416454777122  loss classifier: 0.15165288746356964\n",
      "STEP 1250: loss contrastive :0.0007563012186437845  loss classifier: 0.11864683032035828\n",
      "STEP 1300: loss contrastive :0.0008251076797023416  loss classifier: 0.1428585648536682\n",
      "\n",
      "1334: 0.14450837763842572\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edfd2cfb50346ed9b9b205f9f85e50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008922904962673783  loss classifier: 0.22516782581806183\n",
      "loss contrastive :0.0008801620570011437  loss classifier: 0.2342340350151062\n",
      "loss contrastive :0.0009436492691747844  loss classifier: 0.2321746051311493\n",
      "loss contrastive :0.0008874292252585292  loss classifier: 0.2229316383600235\n",
      "loss contrastive :0.0009319459786638618  loss classifier: 0.2601303458213806\n",
      "loss contrastive :0.0009146207594312727  loss classifier: 0.2369941771030426\n",
      "loss contrastive :0.0009042565943673253  loss classifier: 0.2024374008178711\n",
      "\n",
      "Evaluate loss 0.24233244167906898\n",
      "\n",
      "CPU times: user 55min 33s, sys: 6min 10s, total: 1h 1min 44s\n",
      "Wall time: 56min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set initial loss to infinite\n",
    "import time\n",
    "best_valid_loss = float('inf')\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "now=time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "#for each epoch\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, EPOCHS))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _, _ = evaluate(val_dataloader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f\"./Baseline_abstract_model{now}.pt\")\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081db7d577cc4a6d8095499e331cbe81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65c962f73d848efbaec53b05a597576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0011736995074898005  loss classifier: 0.6784937977790833\n",
      "STEP 50: loss contrastive :0.0010244036093354225  loss classifier: 0.38525381684303284\n",
      "STEP 100: loss contrastive :0.0010459651239216328  loss classifier: 0.34234097599983215\n",
      "STEP 150: loss contrastive :0.0010059644700959325  loss classifier: 0.31425362825393677\n",
      "STEP 200: loss contrastive :0.0009743745322339237  loss classifier: 0.29644834995269775\n",
      "STEP 250: loss contrastive :0.000911412644200027  loss classifier: 0.3009869456291199\n",
      "STEP 300: loss contrastive :0.000994911533780396  loss classifier: 0.2920014560222626\n",
      "STEP 350: loss contrastive :0.0009435606189072132  loss classifier: 0.27130696177482605\n",
      "STEP 550: loss contrastive :0.0009513312834315002  loss classifier: 0.2624566853046417\n",
      "STEP 600: loss contrastive :0.0008490897598676383  loss classifier: 0.2606485188007355\n",
      "STEP 650: loss contrastive :0.0009443267481401563  loss classifier: 0.2466069906949997\n",
      "STEP 700: loss contrastive :0.0009472237434238195  loss classifier: 0.2801697552204132\n",
      "STEP 750: loss contrastive :0.0009368840837851167  loss classifier: 0.2562132775783539\n",
      "STEP 800: loss contrastive :0.0009517501457594335  loss classifier: 0.2913571000099182\n",
      "STEP 850: loss contrastive :0.0010120428632944822  loss classifier: 0.2502491772174835\n",
      "STEP 900: loss contrastive :0.001008233637548983  loss classifier: 0.26180511713027954\n",
      "STEP 950: loss contrastive :0.0008975267992354929  loss classifier: 0.2535405158996582\n",
      "STEP 1000: loss contrastive :0.0009393665241077542  loss classifier: 0.29835718870162964\n",
      "STEP 1050: loss contrastive :0.0009370642947033048  loss classifier: 0.25545239448547363\n",
      "STEP 1100: loss contrastive :0.000973925634752959  loss classifier: 0.250112920999527\n",
      "STEP 1150: loss contrastive :0.0008612530073150992  loss classifier: 0.26104840636253357\n",
      "STEP 1200: loss contrastive :0.0008924937574192882  loss classifier: 0.2545377314090729\n",
      "STEP 1250: loss contrastive :0.0009421527502126992  loss classifier: 0.24482595920562744\n",
      "STEP 1300: loss contrastive :0.0009768663439899683  loss classifier: 0.24315299093723297\n",
      "\n",
      "1334: 0.2857341812456145\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e05d66746d463dac4356dd2fc3b1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.00086324627045542  loss classifier: 0.22190608084201813\n",
      "loss contrastive :0.0008816148620098829  loss classifier: 0.23421892523765564\n",
      "loss contrastive :0.0010400454048067331  loss classifier: 0.2457604855298996\n",
      "loss contrastive :0.0009191778372041881  loss classifier: 0.2457519769668579\n",
      "loss contrastive :0.0009707127464935184  loss classifier: 0.25364264845848083\n",
      "loss contrastive :0.0009471081430092454  loss classifier: 0.23740224540233612\n",
      "loss contrastive :0.000926076085306704  loss classifier: 0.22345615923404694\n",
      "\n",
      "Evaluate loss 0.23963707110711507\n",
      "\n",
      " Epoch 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb08dd1e706547359f9591ee96b74750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0009488399373367429  loss classifier: 0.23232369124889374\n",
      "STEP 50: loss contrastive :0.0008958855760283768  loss classifier: 0.253220796585083\n",
      "STEP 100: loss contrastive :0.0008832403691485524  loss classifier: 0.2489113211631775\n",
      "STEP 150: loss contrastive :0.0009393055224791169  loss classifier: 0.23295415937900543\n",
      "STEP 200: loss contrastive :0.0009999671019613743  loss classifier: 0.2376948744058609\n",
      "STEP 250: loss contrastive :0.0009627904510125518  loss classifier: 0.25691667199134827\n",
      "STEP 300: loss contrastive :0.0008979059057310224  loss classifier: 0.2328859567642212\n",
      "STEP 350: loss contrastive :0.0008929578470997512  loss classifier: 0.22803781926631927\n",
      "STEP 400: loss contrastive :0.0010320055298507214  loss classifier: 0.24067842960357666\n",
      "STEP 450: loss contrastive :0.0009719012305140495  loss classifier: 0.2511763274669647\n",
      "STEP 500: loss contrastive :0.0009282968239858747  loss classifier: 0.24083101749420166\n",
      "STEP 550: loss contrastive :0.0008754656882956624  loss classifier: 0.2232983559370041\n",
      "STEP 600: loss contrastive :0.0008369518909603357  loss classifier: 0.227905735373497\n",
      "STEP 650: loss contrastive :0.0009327534353360534  loss classifier: 0.22973594069480896\n",
      "STEP 700: loss contrastive :0.000927383778616786  loss classifier: 0.21701186895370483\n",
      "STEP 750: loss contrastive :0.0008915961370803416  loss classifier: 0.23167774081230164\n",
      "STEP 800: loss contrastive :0.0009137419983744621  loss classifier: 0.23212331533432007\n",
      "STEP 850: loss contrastive :0.0008943690918385983  loss classifier: 0.23854492604732513\n",
      "STEP 900: loss contrastive :0.0009501170716248453  loss classifier: 0.21960677206516266\n",
      "STEP 950: loss contrastive :0.0009552448755130172  loss classifier: 0.2359723597764969\n",
      "STEP 1000: loss contrastive :0.000886697496753186  loss classifier: 0.23530149459838867\n",
      "STEP 1050: loss contrastive :0.0009854263626039028  loss classifier: 0.24442051351070404\n",
      "STEP 1100: loss contrastive :0.0009401102433912456  loss classifier: 0.23766712844371796\n",
      "STEP 1150: loss contrastive :0.000903163687326014  loss classifier: 0.23047256469726562\n",
      "STEP 1200: loss contrastive :0.0008468367159366608  loss classifier: 0.21468748152256012\n",
      "STEP 1250: loss contrastive :0.0008843366522341967  loss classifier: 0.2243933528661728\n",
      "STEP 1300: loss contrastive :0.0009589018300175667  loss classifier: 0.23291292786598206\n",
      "\n",
      "1334: 0.23178507207931204\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c614c6adb7c41878b21a5bf808e2807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008599188877269626  loss classifier: 0.2006521224975586\n",
      "loss contrastive :0.0008460755925625563  loss classifier: 0.2135000228881836\n",
      "loss contrastive :0.000979618402197957  loss classifier: 0.22505564987659454\n",
      "loss contrastive :0.0008922427077777684  loss classifier: 0.22128352522850037\n",
      "loss contrastive :0.0010183851700276136  loss classifier: 0.24932970106601715\n",
      "loss contrastive :0.000922065693885088  loss classifier: 0.22875399887561798\n",
      "loss contrastive :0.0009104629280045629  loss classifier: 0.19750604033470154\n",
      "\n",
      "Evaluate loss 0.22413069563252586\n",
      "\n",
      " Epoch 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b3a84c364d467e84459a7181919547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0008980465936474502  loss classifier: 0.22032979130744934\n",
      "STEP 50: loss contrastive :0.0009284426923841238  loss classifier: 0.20918573439121246\n",
      "STEP 100: loss contrastive :0.000885294983163476  loss classifier: 0.2093435525894165\n",
      "STEP 150: loss contrastive :0.0008536387467756867  loss classifier: 0.2002076506614685\n",
      "STEP 200: loss contrastive :0.0008916630176827312  loss classifier: 0.22726105153560638\n",
      "STEP 250: loss contrastive :0.0008259156020358205  loss classifier: 0.1979772448539734\n",
      "STEP 300: loss contrastive :0.0009368800092488527  loss classifier: 0.2023366093635559\n",
      "STEP 350: loss contrastive :0.0009978469461202621  loss classifier: 0.22486214339733124\n",
      "STEP 400: loss contrastive :0.0009512822143733501  loss classifier: 0.21411678194999695\n",
      "STEP 450: loss contrastive :0.0009087007492780685  loss classifier: 0.20623838901519775\n",
      "STEP 500: loss contrastive :0.0009110539685934782  loss classifier: 0.19071035087108612\n",
      "STEP 550: loss contrastive :0.001022130949422717  loss classifier: 0.22776824235916138\n",
      "STEP 600: loss contrastive :0.000917917350307107  loss classifier: 0.222357839345932\n",
      "STEP 650: loss contrastive :0.0009150479454547167  loss classifier: 0.22849297523498535\n",
      "STEP 700: loss contrastive :0.0008697551675140858  loss classifier: 0.2075357884168625\n",
      "STEP 750: loss contrastive :0.0008842159295454621  loss classifier: 0.2006600797176361\n",
      "STEP 800: loss contrastive :0.000907926878426224  loss classifier: 0.2176223248243332\n",
      "STEP 850: loss contrastive :0.0008957922109402716  loss classifier: 0.19320987164974213\n",
      "STEP 900: loss contrastive :0.0008517869282513857  loss classifier: 0.19495932757854462\n",
      "STEP 950: loss contrastive :0.0009135412983596325  loss classifier: 0.21300384402275085\n",
      "STEP 1000: loss contrastive :0.0008291336707770824  loss classifier: 0.22137853503227234\n",
      "STEP 1050: loss contrastive :0.0008741163183003664  loss classifier: 0.1819954812526703\n",
      "STEP 1100: loss contrastive :0.0009068308863788843  loss classifier: 0.21869130432605743\n",
      "STEP 1150: loss contrastive :0.0009539425373077393  loss classifier: 0.20992732048034668\n",
      "STEP 1200: loss contrastive :0.0009187277755700052  loss classifier: 0.1884355992078781\n",
      "STEP 1250: loss contrastive :0.0009197737090289593  loss classifier: 0.19881734251976013\n",
      "STEP 1300: loss contrastive :0.0008159006247296929  loss classifier: 0.20219449698925018\n",
      "\n",
      "1334: 0.20851367177364977\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fbe53b7b54489896e3af142acdcb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008725500083528459  loss classifier: 0.20578263700008392\n",
      "loss contrastive :0.000910047092474997  loss classifier: 0.21890391409397125\n",
      "loss contrastive :0.0009645494865253568  loss classifier: 0.2212047576904297\n",
      "loss contrastive :0.0009276264463551342  loss classifier: 0.2225142866373062\n",
      "loss contrastive :0.0010248979087918997  loss classifier: 0.24798201024532318\n",
      "loss contrastive :0.0009418590925633907  loss classifier: 0.21279238164424896\n",
      "loss contrastive :0.0009347681188955903  loss classifier: 0.18822413682937622\n",
      "\n",
      "Evaluate loss 0.22210357636213302\n",
      "\n",
      " Epoch 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef069f9af29469588ebbd7c6c36c103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.000942211365327239  loss classifier: 0.18686386942863464\n",
      "STEP 50: loss contrastive :0.0008771411376073956  loss classifier: 0.168535053730011\n",
      "STEP 100: loss contrastive :0.0009232746670022607  loss classifier: 0.17536720633506775\n",
      "STEP 150: loss contrastive :0.0009367841412313282  loss classifier: 0.15939436852931976\n",
      "STEP 200: loss contrastive :0.0008358241757377982  loss classifier: 0.20461532473564148\n",
      "STEP 250: loss contrastive :0.0008678673766553402  loss classifier: 0.176971897482872\n",
      "STEP 300: loss contrastive :0.000818393484223634  loss classifier: 0.15583422780036926\n",
      "STEP 350: loss contrastive :0.0008111900533549488  loss classifier: 0.176048144698143\n",
      "STEP 400: loss contrastive :0.0007947029080241919  loss classifier: 0.17967219650745392\n",
      "STEP 450: loss contrastive :0.0008485829457640648  loss classifier: 0.18107275664806366\n",
      "STEP 500: loss contrastive :0.000850270502269268  loss classifier: 0.17511844635009766\n",
      "STEP 550: loss contrastive :0.0008164546452462673  loss classifier: 0.18557403981685638\n",
      "STEP 600: loss contrastive :0.0009128558449447155  loss classifier: 0.18678396940231323\n",
      "STEP 650: loss contrastive :0.0009649867424741387  loss classifier: 0.19543366134166718\n",
      "STEP 700: loss contrastive :0.0009263024548999965  loss classifier: 0.18813340365886688\n",
      "STEP 750: loss contrastive :0.0008957870886661112  loss classifier: 0.18359319865703583\n",
      "STEP 800: loss contrastive :0.0008358509512618184  loss classifier: 0.18222005665302277\n",
      "STEP 850: loss contrastive :0.0008834587060846388  loss classifier: 0.17140616476535797\n",
      "STEP 900: loss contrastive :0.0008425001287832856  loss classifier: 0.19489166140556335\n",
      "STEP 950: loss contrastive :0.0009731538593769073  loss classifier: 0.18568919599056244\n",
      "STEP 1000: loss contrastive :0.0008747252286411822  loss classifier: 0.1568465679883957\n",
      "STEP 1050: loss contrastive :0.0008505711448378861  loss classifier: 0.19135193526744843\n",
      "STEP 1100: loss contrastive :0.0009187135146930814  loss classifier: 0.1793641597032547\n",
      "STEP 1150: loss contrastive :0.0008155541145242751  loss classifier: 0.18359552323818207\n",
      "STEP 1200: loss contrastive :0.0008373362361453474  loss classifier: 0.18632934987545013\n",
      "STEP 1250: loss contrastive :0.0008826848934404552  loss classifier: 0.18996219336986542\n",
      "STEP 1300: loss contrastive :0.0009075968409888446  loss classifier: 0.17624488472938538\n",
      "\n",
      "1334: 0.18130031145467293\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddb8ba18f1847f8a572667163d27b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0008937601232901216  loss classifier: 0.2024717777967453\n",
      "loss contrastive :0.0009234985336661339  loss classifier: 0.22096052765846252\n",
      "loss contrastive :0.0009677024208940566  loss classifier: 0.22529539465904236\n",
      "loss contrastive :0.0009381117415614426  loss classifier: 0.21840733289718628\n",
      "loss contrastive :0.001024402561597526  loss classifier: 0.25764214992523193\n",
      "loss contrastive :0.000994328293018043  loss classifier: 0.2228819578886032\n",
      "loss contrastive :0.000939505931455642  loss classifier: 0.1843181699514389\n",
      "\n",
      "Evaluate loss 0.22800866003547396\n",
      "\n",
      " Epoch 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975dab97c06646138119634ba1742b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train', max=1335.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: loss contrastive :0.0007900340715423226  loss classifier: 0.15494336187839508\n",
      "STEP 50: loss contrastive :0.0008160884608514607  loss classifier: 0.15528662502765656\n",
      "STEP 100: loss contrastive :0.0008477926021441817  loss classifier: 0.16335934400558472\n",
      "STEP 150: loss contrastive :0.0008415866177529097  loss classifier: 0.14178107678890228\n",
      "STEP 200: loss contrastive :0.0008564976742491126  loss classifier: 0.18279756605625153\n",
      "STEP 250: loss contrastive :0.0008687674999237061  loss classifier: 0.1595715433359146\n",
      "STEP 300: loss contrastive :0.0009081882890313864  loss classifier: 0.16121934354305267\n",
      "STEP 350: loss contrastive :0.0006919500301592052  loss classifier: 0.13182401657104492\n",
      "STEP 400: loss contrastive :0.0008912598132155836  loss classifier: 0.15460121631622314\n",
      "STEP 450: loss contrastive :0.0007779154693707824  loss classifier: 0.1831590086221695\n",
      "STEP 500: loss contrastive :0.0008356108446605504  loss classifier: 0.16439509391784668\n",
      "STEP 550: loss contrastive :0.0008153213420882821  loss classifier: 0.15982994437217712\n",
      "STEP 600: loss contrastive :0.0007930166320875287  loss classifier: 0.1499931961297989\n",
      "STEP 650: loss contrastive :0.0008776435279287398  loss classifier: 0.17778578400611877\n",
      "STEP 700: loss contrastive :0.000851315853651613  loss classifier: 0.15625931322574615\n",
      "STEP 750: loss contrastive :0.0007686999160796404  loss classifier: 0.1308041363954544\n",
      "STEP 800: loss contrastive :0.0008525163866579533  loss classifier: 0.1466894894838333\n",
      "STEP 850: loss contrastive :0.0007661130512133241  loss classifier: 0.14178267121315002\n",
      "STEP 900: loss contrastive :0.0007489171694032848  loss classifier: 0.15259340405464172\n",
      "STEP 950: loss contrastive :0.0007311141234822571  loss classifier: 0.14152930676937103\n",
      "STEP 1000: loss contrastive :0.0008320212946273386  loss classifier: 0.15096232295036316\n",
      "STEP 1050: loss contrastive :0.0008164399187080562  loss classifier: 0.13335980474948883\n",
      "STEP 1100: loss contrastive :0.0007713154191151261  loss classifier: 0.14753103256225586\n",
      "STEP 1150: loss contrastive :0.0008120735874399543  loss classifier: 0.16490334272384644\n",
      "STEP 1200: loss contrastive :0.0007694274536333978  loss classifier: 0.14890806376934052\n",
      "STEP 1250: loss contrastive :0.0006670518778264523  loss classifier: 0.1237284392118454\n",
      "STEP 1300: loss contrastive :0.0008364875102415681  loss classifier: 0.15063519775867462\n",
      "\n",
      "1334: 0.1502600369381994\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e893d67efe0436db9a49450f4c988df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval', max=70.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0009505008347332478  loss classifier: 0.21422308683395386\n",
      "loss contrastive :0.000962299294769764  loss classifier: 0.22596541047096252\n",
      "loss contrastive :0.0009981528855860233  loss classifier: 0.2330978512763977\n",
      "loss contrastive :0.000995664857327938  loss classifier: 0.22896067798137665\n",
      "loss contrastive :0.00106520252302289  loss classifier: 0.26746976375579834\n",
      "loss contrastive :0.0010346363997086883  loss classifier: 0.23680955171585083\n",
      "loss contrastive :0.0009839585982263088  loss classifier: 0.19763624668121338\n",
      "\n",
      "Evaluate loss 0.24067499275718415\n",
      "\n",
      "CPU times: user 1h 10min 51s, sys: 17min 12s, total: 1h 28min 4s\n",
      "Wall time: 1h 22min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set initial loss to infinite\n",
    "import time\n",
    "best_valid_loss = float('inf')\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "now=time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "#for each epoch\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, EPOCHS))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _, _ = evaluate(val_dataloader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f\"./Baseline_abstract_model{now}.pt\")\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score)\n",
    "\n",
    "\n",
    "true = np.array(total_labels)\n",
    "pred = np.array(total_preds>0.5)\n",
    "\n",
    "dic = {\n",
    "    \"Accuracy\" : accuracy_score(true,pred),\n",
    "    \"Precision-micro\" : precision_score(true,pred,average='micro'),\n",
    "    \"Precision-macro\" : precision_score(true,pred,average='macro'),\n",
    "    \"recall-micro\" : recall_score(true,pred,average='micro'),\n",
    "    \"recall-macro\" : recall_score(true,pred,average='macro'),\n",
    "    \"f1_micro\" : f1_score(true,pred,average='micro'),\n",
    "    \"f1-macro\" : f1_score(true,pred,average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.3918269230769231,\n",
       " 'Precision-micro': 0.797971259509721,\n",
       " 'Precision-macro': 0.41194663692126593,\n",
       " 'recall-micro': 0.5137135393992164,\n",
       " 'recall-macro': 0.2568275311949758,\n",
       " 'f1_micro': 0.6250413825067869,\n",
       " 'f1-macro': 0.2996674369295113}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch_size = 8时的模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./model/Classfication_Baseline_claims_model2022-02-22 01:57:06.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_feather(\"2021-sample-50000.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee8a6b28b664692b32f210cbc05d913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss contrastive :0.0005801975494250655  loss classifier: 0.0064818039536476135\n",
      "loss contrastive :0.0005945584853179753  loss classifier: 0.00567277567461133\n",
      "Evaluate loss 0.005462370702589024\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PatentDataset(\n",
    "  test_df,\n",
    "  tokenizer,\n",
    "  max_token_len=128\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False,drop_last=True)\n",
    "\n",
    "avg_loss, total_preds, total_labels = evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 ms, sys: 68 µs, total: 19.9 ms\n",
      "Wall time: 17.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time output = model.bert(input_ids=input_ids,attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = test_df['publication_title'][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tokenizer.encode_plus(\n",
    "                query,        \n",
    "                max_length=128,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "input_ids = query['input_ids'].to(device)\n",
    "attention_mask=query['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "164dc99c25814f6ab80b1620d5bbdccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_5445e44543df4f0593767b43681f48f0",
       "max": 86055,
       "style": "IPY_MODEL_ccb7249e92c14924821f89b126e0cacd",
       "value": 85982
      }
     },
     "1d50adeb23e542a5aa98f7de96d6a9d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1e895d0af15b4ff2a6c2ad14a91f5748": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_c903ce8ed8c54437b67158c54da3a22a",
       "max": 10757,
       "style": "IPY_MODEL_f8a513de577440318b252bef4f2da141",
       "value": 9544
      }
     },
     "20a637e61a934dc3a1c79ed24c7cecd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6ec90b1f56454be6b23a9bbfc75ffcf1",
       "style": "IPY_MODEL_6d5cbecbab2a45b28710fe24e4ac6de6",
       "value": " 85982/86055 [11:24:22&lt;00:35,  2.06it/s]"
      }
     },
     "2748d0831de24a3288e63ff82496a7d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_90cfa066ef354ea2b1ee38ef9a5f8099",
       "max": 5,
       "style": "IPY_MODEL_593f5fe9c83d4b85a4fbd9fd447b8e9a"
      }
     },
     "2b90dffa457c429f99c92d510b048761": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "309c7152a11d4c1381a88e9c451751c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "37e133be36cf4b31a6e83448ade7534b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_728b2a6ea0f0465282eb7464e28b8f85",
       "max": 86055,
       "style": "IPY_MODEL_1d50adeb23e542a5aa98f7de96d6a9d7",
       "value": 44175
      }
     },
     "3896630326114e08b072c857b038bc1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a7d8d6da3f54f238b0afea6e7ee2b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a467379af6fb4610af04419257bcd97e",
       "style": "IPY_MODEL_2b90dffa457c429f99c92d510b048761",
       "value": "Eval:  89%"
      }
     },
     "3ae8ae0bda93481196c4f129a01bf000": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f50ae3f29d31451f941bca0d4a03a215",
       "style": "IPY_MODEL_8ee2175173904a2eb2d9aba4753e15d6",
       "value": " 44175/86055 [5:52:16&lt;4:55:35,  2.36it/s]"
      }
     },
     "4314a58991154b8e862b9b2e0aebef2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f12a82db3205424182376a8b167778d1",
        "IPY_MODEL_37e133be36cf4b31a6e83448ade7534b",
        "IPY_MODEL_3ae8ae0bda93481196c4f129a01bf000"
       ],
       "layout": "IPY_MODEL_3896630326114e08b072c857b038bc1a"
      }
     },
     "434444785a7e447e87e0cad98313ad1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5445e44543df4f0593767b43681f48f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "556f902dd03b49fbb6bf7120e444631e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "573e3df279c94dcdbcca6d4fbc2baba5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "593f5fe9c83d4b85a4fbd9fd447b8e9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6c8675f1019348b090dcfd9a695e28ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6d5cbecbab2a45b28710fe24e4ac6de6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6ec90b1f56454be6b23a9bbfc75ffcf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ef42ab2cf214b2a9c161320cab5eaf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e5da622f865b4be589d33d9bf11bff95",
       "style": "IPY_MODEL_309c7152a11d4c1381a88e9c451751c9",
       "value": "  0%"
      }
     },
     "728b2a6ea0f0465282eb7464e28b8f85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8ee2175173904a2eb2d9aba4753e15d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "90cfa066ef354ea2b1ee38ef9a5f8099": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9820aa3240884437b73ec6ac97f9bfeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a7a893bdc5b4996bb0af662499a1031": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3a7d8d6da3f54f238b0afea6e7ee2b85",
        "IPY_MODEL_1e895d0af15b4ff2a6c2ad14a91f5748",
        "IPY_MODEL_d8a58dc7a14847c380437b483941f7b8"
       ],
       "layout": "IPY_MODEL_bb728dc1babb44c59b277d6c0fae77d1"
      }
     },
     "9acb681f98d74355b0d50fd3392c7ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3685fa7e19d4cc78a84fe0f9a47d392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a467379af6fb4610af04419257bcd97e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad8d9ad1431f4ab2961b70feb3bffef4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb728dc1babb44c59b277d6c0fae77d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c0bbf35d93224082a7f0abddb98cecf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c15c1985d6914f08b96560a7231ee0ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3685fa7e19d4cc78a84fe0f9a47d392",
       "style": "IPY_MODEL_434444785a7e447e87e0cad98313ad1f",
       "value": " 0/5 [00:00&lt;?, ?it/s]"
      }
     },
     "c903ce8ed8c54437b67158c54da3a22a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ccb7249e92c14924821f89b126e0cacd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d5e99427fc1a466589e96bf94e2e0b89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6ef42ab2cf214b2a9c161320cab5eaf4",
        "IPY_MODEL_2748d0831de24a3288e63ff82496a7d9",
        "IPY_MODEL_c15c1985d6914f08b96560a7231ee0ae"
       ],
       "layout": "IPY_MODEL_c0bbf35d93224082a7f0abddb98cecf8"
      }
     },
     "d8a58dc7a14847c380437b483941f7b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ad8d9ad1431f4ab2961b70feb3bffef4",
       "style": "IPY_MODEL_f1587b8254aa4fe995d0262ff5c0ff0d",
       "value": " 9544/10757 [25:20&lt;03:20,  6.06it/s]"
      }
     },
     "e5da622f865b4be589d33d9bf11bff95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6911c72c9fb4701bf09e05c358cc971": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f16d3926bf7d42f3a864c8aaf75d8fa2",
        "IPY_MODEL_164dc99c25814f6ab80b1620d5bbdccb",
        "IPY_MODEL_20a637e61a934dc3a1c79ed24c7cecd1"
       ],
       "layout": "IPY_MODEL_573e3df279c94dcdbcca6d4fbc2baba5"
      }
     },
     "f12a82db3205424182376a8b167778d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9820aa3240884437b73ec6ac97f9bfeb",
       "style": "IPY_MODEL_6c8675f1019348b090dcfd9a695e28ca",
       "value": "Train:  49%"
      }
     },
     "f1587b8254aa4fe995d0262ff5c0ff0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f16d3926bf7d42f3a864c8aaf75d8fa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9acb681f98d74355b0d50fd3392c7ec2",
       "style": "IPY_MODEL_556f902dd03b49fbb6bf7120e444631e",
       "value": "Train: 100%"
      }
     },
     "f50ae3f29d31451f941bca0d4a03a215": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f8a513de577440318b252bef4f2da141": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
